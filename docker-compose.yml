x-build-args: &cu118_args
  PIP_EXTRA_INDEX_URL: https://download.pytorch.org/whl/cu118


services:
  ai_vols_init:
    image: alpine:3.20
    container_name: ai_vols_init
    restart: "no"
    command:
      - sh
      - -lc
      - |
        set -e

        # MODELS
        if [ -e /ai-vols/models ] && [ ! -d /ai-vols/models ]; then echo "ERROR: /ai-vols/models exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/models

        if [ -e /ai-vols/models/film2 ] && [ ! -d /ai-vols/models/film2 ]; then echo "ERROR: /ai-vols/models/film2 exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/models/film2

        if [ -e /ai-vols/models/comfyui ] && [ ! -d /ai-vols/models/comfyui ]; then echo "ERROR: /ai-vols/models/comfyui exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/models/comfyui

        if [ -e /ai-vols/models/hf_cache ] && [ ! -d /ai-vols/models/hf_cache ]; then echo "ERROR: /ai-vols/models/hf_cache exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/models/hf_cache

        if [ -e /ai-vols/models/torch_cache ] && [ ! -d /ai-vols/models/torch_cache ]; then echo "ERROR: /ai-vols/models/torch_cache exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/models/torch_cache

        if [ -e /ai-vols/models/tts_cache ] && [ ! -d /ai-vols/models/tts_cache ]; then echo "ERROR: /ai-vols/models/tts_cache exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/models/tts_cache

        if [ -e /ai-vols/models/demucs_cache ] && [ ! -d /ai-vols/models/demucs_cache ]; then echo "ERROR: /ai-vols/models/demucs_cache exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/models/demucs_cache

        if [ -e /ai-vols/models/ollama ] && [ ! -d /ai-vols/models/ollama ]; then echo "ERROR: /ai-vols/models/ollama exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/models/ollama

        if [ -e /ai-vols/models/ollama/qwen ] && [ ! -d /ai-vols/models/ollama/qwen ]; then echo "ERROR: /ai-vols/models/ollama/qwen exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/models/ollama/qwen

        if [ -e /ai-vols/models/ollama/glm ] && [ ! -d /ai-vols/models/ollama/glm ]; then echo "ERROR: /ai-vols/models/ollama/glm exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/models/ollama/glm

        if [ -e /ai-vols/models/ollama/deepseek ] && [ ! -d /ai-vols/models/ollama/deepseek ]; then echo "ERROR: /ai-vols/models/ollama/deepseek exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/models/ollama/deepseek

        if [ -e /ai-vols/models/rvc_models ] && [ ! -d /ai-vols/models/rvc_models ]; then echo "ERROR: /ai-vols/models/rvc_models exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/models/rvc_models

        if [ -e /ai-vols/models/rvc_assets ] && [ ! -d /ai-vols/models/rvc_assets ]; then echo "ERROR: /ai-vols/models/rvc_assets exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/models/rvc_assets

        # TRAINING DATA
        if [ -e /ai-vols/training_data ] && [ ! -d /ai-vols/training_data ]; then echo "ERROR: /ai-vols/training_data exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/training_data

        if [ -e /ai-vols/training_data/film2 ] && [ ! -d /ai-vols/training_data/film2 ]; then echo "ERROR: /ai-vols/training_data/film2 exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/training_data/film2

        if [ -e /ai-vols/training_data/rvc ] && [ ! -d /ai-vols/training_data/rvc ]; then echo "ERROR: /ai-vols/training_data/rvc exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/training_data/rvc

        # ARTIFACTS
        if [ -e /ai-vols/artifacts ] && [ ! -d /ai-vols/artifacts ]; then echo "ERROR: /ai-vols/artifacts exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/artifacts

        if [ -e /ai-vols/artifacts/images ] && [ ! -d /ai-vols/artifacts/images ]; then echo "ERROR: /ai-vols/artifacts/images exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/artifacts/images

        if [ -e /ai-vols/artifacts/videos ] && [ ! -d /ai-vols/artifacts/videos ]; then echo "ERROR: /ai-vols/artifacts/videos exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/artifacts/videos

        if [ -e /ai-vols/artifacts/audio ] && [ ! -d /ai-vols/artifacts/audio ]; then echo "ERROR: /ai-vols/artifacts/audio exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/artifacts/audio

        if [ -e /ai-vols/artifacts/tmp ] && [ ! -d /ai-vols/artifacts/tmp ]; then echo "ERROR: /ai-vols/artifacts/tmp exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/artifacts/tmp

        if [ -e /ai-vols/artifacts/manifests ] && [ ! -d /ai-vols/artifacts/manifests ]; then echo "ERROR: /ai-vols/artifacts/manifests exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/artifacts/manifests

        if [ -e /ai-vols/artifacts/logs ] && [ ! -d /ai-vols/artifacts/logs ]; then echo "ERROR: /ai-vols/artifacts/logs exists but not a dir" >&2; exit 2; fi
        mkdir -p /ai-vols/artifacts/logs

        echo "[ai_vols_init] OK"
    volumes:
      - /mnt/ai-vols:/ai-vols





  film2_bootstrap:
    image: python:3.11-slim
    container_name: film2_bootstrap
    depends_on:
      ai_vols_init:
        condition: service_completed_successfully
    command: ["/bin/bash","-lc","/bin/bash /bootstrap/bootstrap_models.sh"]
    environment:
      - FILM2_MODELS=/opt/models
      - HF_HOME=/opt/models/.hf
      - TRANSFORMERS_CACHE=/opt/models/.hf
      - TORCH_HOME=/opt/models/.torch
      - HF_HUB_ENABLE_PROGRESS_BARS=1
      - HF_HUB_ENABLE_XET=0
      - HF_MAX_WORKERS=4
      - SKIP_SVD=1
      - MUSIC_ENGINE_REPO=${MUSIC_ENGINE_REPO:-}
      - MUSIC_ENGINE_TARBALL_URL=${MUSIC_ENGINE_TARBALL_URL:-}
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN:-}
    volumes:
      - /mnt/ai-vols/models/film2:/opt/models
      - ./bootstrap:/bootstrap:ro
      - /mnt/ai-vols/artifacts:/workspace/uploads
    restart: "no"

  rvc_python:
    build:
      context: ./services/rvc_python
      dockerfile: Dockerfile
    container_name: rvc_python
    restart: unless-stopped
    runtime: nvidia
    devices:
      - "nvidia.com/gpu=all"
    depends_on:
      film2_bootstrap:
        condition: service_completed_successfully
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - PYTHONUNBUFFERED=1
      - LOG_DIR=/workspace/logs
      - LOG_LEVEL=${RVC_LOG_LEVEL:-DEBUG}
    volumes:
      - /mnt/ai-vols/models/rvc_models:/srv/rvc_models
      - /mnt/ai-vols/models/film2:/opt/models:ro
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs
    network_mode: host
    expose:
      - "5050"

  rvc_trainer:
    build:
      context: ./services/rvc_trainer
      dockerfile: Dockerfile
    container_name: rvc_trainer
    restart: unless-stopped
    runtime: nvidia
    devices:
      - "nvidia.com/gpu=all"
    depends_on:
      film2_bootstrap:
        condition: service_completed_successfully
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - PYTHONUNBUFFERED=1
      - LOG_DIR=/workspace/logs
      - LOG_LEVEL=${RVC_LOG_LEVEL:-DEBUG}
      - RVC_TRAIN_DATA_ROOT=/srv/data
      - RVC_MODELS_ROOT=/srv/rvc_models
      - RVC_WEBUI_ROOT=/srv/rvc_webui
      - RVC_DEFAULT_MALE_VOICE_ID=${RVC_DEFAULT_MALE_VOICE_ID:-TITAN}
      - RVC_DEFAULT_FEMALE_VOICE_ID=${RVC_DEFAULT_FEMALE_VOICE_ID:-TITAN}
    volumes:
      - /mnt/ai-vols/models/film2:/opt/models:ro
      - /mnt/ai-vols/models/rvc_models:/srv/rvc_models
      - /mnt/ai-vols/training_data/rvc:/srv/data
      - rvc_logs:/srv/logs
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs
    network_mode: host
    expose:
      - "7070"

  rvc:
    build:
      context: .
      dockerfile: services/rvc/Dockerfile
    container_name: rvc_service
    restart: unless-stopped
    runtime: nvidia
    devices:
      - "nvidia.com/gpu=all"
    depends_on:
      - rvc_python
      - rvc_trainer
    environment:
      - NVIDIA_VISIBLE_DEVICES=${MUSIC_GPU:-all}
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - PYTHONUNBUFFERED=1
      - RVC_MODEL_ROOT=/opt/models/rvc_titan
      - RVC_REGISTRY_PATH=/rvc/assets/registry.json
      - RVC_VOICES_ROOT=/rvc/assets/voices
      - RVC_ENGINE_BASE=http://127.0.0.1:5050
      - RVC_TRAINER_BASE=http://127.0.0.1:7070
      - RVC_MODELS_ROOT=/srv/rvc_models
      - RVC_DEFAULT_MALE_VOICE_ID=${RVC_DEFAULT_MALE_VOICE_ID:-TITAN}
      - RVC_DEFAULT_FEMALE_VOICE_ID=${RVC_DEFAULT_FEMALE_VOICE_ID:-TITAN}
      - DEMUCS_API_URL=http://127.0.0.1:9101
      - WHISPER_API_URL=http://127.0.0.1:7861
      - VOCALFIX_API_URL=http://127.0.0.1:7866
      - LOG_DIR=/workspace/logs
      - LOG_LEVEL=${RVC_LOG_LEVEL:-DEBUG}
    network_mode: host
    expose:
      - "7863"
    volumes:
      - /mnt/ai-vols/models/film2:/opt/models:ro
      - /mnt/ai-vols/models/rvc_assets:/rvc/assets
      - /mnt/ai-vols/models/rvc_models:/srv/rvc_models
      - /mnt/ai-vols/training_data/rvc:/srv/data
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs

  vocalfix:
    build:
      context: .
      dockerfile: services/vocalfix/Dockerfile
    container_name: vocalfix_service
    restart: unless-stopped
    runtime: nvidia
    devices:
      - "nvidia.com/gpu=all"
    environment:
      - NVIDIA_VISIBLE_DEVICES=${MUSIC_GPU:-all}
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - LOG_DIR=/workspace/logs
    network_mode: host
    expose:
      - "7864"
    volumes:
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs

  pgvector:
    network_mode: host
    image: pgvector/pgvector:0.7.4-pg16
    container_name: pgvector_db
    restart: unless-stopped
    environment:
      - POSTGRES_DB=ragdb
      - POSTGRES_USER=rag
      - POSTGRES_PASSWORD=ragpass
      - LOG_DIR=/workspace/logs
    volumes:
      - pgvector_data:/var/lib/postgresql/data
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs

  ollama_qwen:
    network_mode: host
    image: ollama/ollama:latest
    pull_policy: always
    container_name: ollama_qwen
    restart: unless-stopped
    runtime: nvidia
    devices:
      - "nvidia.com/gpu=all"
    environment:
      - OLLAMA_HOST=0.0.0.0:11435
      - OLLAMA_KEEP_ALIVE=24h
      - NVIDIA_VISIBLE_DEVICES=${OLLAMA_QWEN_GPU:-all}
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - /mnt/ai-vols/models/ollama/qwen:/root/.ollama
      - /mnt/ai-vols/artifacts:/workspace/uploads

  init_qwen:
    image: curlimages/curl:8.7.1
    container_name: init_qwen
    network_mode: host
    depends_on:
      - ollama_qwen
    environment:
      - QWEN_MODEL_ID=${QWEN_MODEL_ID:-huihui_ai/qwen3-abliterated:30b-a3b-q4_K_M}
    command: ["sh","-lc","until curl -sf http://127.0.0.1:11435/api/tags >/dev/null; do sleep 2; done; echo Pulling $QWEN_MODEL_ID; curl -sf -X POST http://127.0.0.1:11435/api/pull -H 'Content-Type: application/json' -d '{\"name\":\"${QWEN_MODEL_ID}\"}'; echo Pulled $QWEN_MODEL_ID"]

  glm_ollama:
    network_mode: host
    image: ollama/ollama:latest
    pull_policy: always
    container_name: glm_ollama
    restart: unless-stopped
    runtime: nvidia
    devices:
      - "nvidia.com/gpu=all"
    environment:
      - OLLAMA_HOST=0.0.0.0:11433
      - OLLAMA_KEEP_ALIVE=24h
      - NVIDIA_VISIBLE_DEVICES=${OLLAMA_GLM_GPU:-all}
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - /mnt/ai-vols/models/ollama/glm:/root/.ollama
      - /mnt/ai-vols/artifacts:/workspace/uploads

  deepseek_ollama:
    network_mode: host
    image: ollama/ollama:latest
    pull_policy: always
    container_name: deepseek_ollama
    restart: unless-stopped
    runtime: nvidia
    devices:
      - "nvidia.com/gpu=all"
    environment:
      - OLLAMA_HOST=0.0.0.0:11436
      - OLLAMA_KEEP_ALIVE=24h
      - NVIDIA_VISIBLE_DEVICES=${OLLAMA_DEEPSEEK_GPU:-all}
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - /mnt/ai-vols/models/ollama/deepseek:/root/.ollama
      - /mnt/ai-vols/artifacts:/workspace/uploads

  init_glm:
    image: curlimages/curl:8.7.1
    container_name: init_glm
    network_mode: host
    depends_on:
      - glm_ollama
    environment:
      - GLM_MODEL_ID=${GLM_MODEL_ID:-hf.co/unsloth/GLM-4.6V-Flash-GGUF:BF16}
    command: ["sh","-lc","until curl -s http://127.0.0.1:11433/api/tags >/dev/null; do sleep 2; done; echo Pulling $GLM_MODEL_ID; curl -s -X POST http://127.0.0.1:11433/api/pull -H 'Content-Type: application/json' -d '{\"name\":\"${GLM_MODEL_ID:-hf.co/unsloth/GLM-4.6V-Flash-GGUF:BF16}\"}'; echo Pulled $GLM_MODEL_ID"]

  init_deepseek:
    image: curlimages/curl:8.7.1
    container_name: init_deepseek
    network_mode: host
    depends_on:
      - deepseek_ollama
    environment:
      - DEEPSEEK_CODER_MODEL_ID=${DEEPSEEK_CODER_MODEL_ID:-huihui_ai/deepseek-r1-abliterated:32b}
    command: ["sh","-lc","until curl -s http://127.0.0.1:11436/api/tags >/dev/null; do sleep 2; done; echo Pulling $DEEPSEEK_CODER_MODEL_ID; curl -s -X POST http://127.0.0.1:11436/api/pull -H 'Content-Type: application/json' -d '{\"name\":\"${DEEPSEEK_CODER_MODEL_ID:-huihui_ai/deepseek-r1-abliterated:32b}\"}'; echo Pulled $DEEPSEEK_CODER_MODEL_ID"]

  init_qwen_vl:
    image: curlimages/curl:8.7.1
    container_name: init_qwen_vl
    network_mode: host
    depends_on:
      - ollama_qwen
    environment:
      - QWEN_VL_MODEL_ID=${QWEN_VL_MODEL_ID:-huihui_ai/qwen3-vl-abliterated:30b-a3b-Thinking-v2-q4_K_M}
    command: ["sh","-lc","until curl -sf http://127.0.0.1:11435/api/tags >/dev/null; do sleep 2; done; echo Pulling $QWEN_VL_MODEL_ID; curl -sf -X POST http://127.0.0.1:11435/api/pull -H 'Content-Type: application/json' -d '{\"name\":\"${QWEN_VL_MODEL_ID:-huihui_ai/qwen3-vl-abliterated:30b-a3b-Thinking-v2-q4_K_M}\"}'; echo Pulled $QWEN_VL_MODEL_ID"]

  orchestrator:
    build:
      context: .
      dockerfile: orchestrator/Dockerfile
      args:
        <<: *cu118_args
    container_name: void_orchestrator
    restart: unless-stopped
    network_mode: host
    depends_on:
      ai_vols_init:
        condition: service_completed_successfully
    environment:
      - PYTHONUNBUFFERED=1
      - ORCH_LOG_LEVEL=${ORCH_LOG_LEVEL:-DEBUG}
      - ORCH_THIRD_PARTY_LOG_LEVEL=${ORCH_THIRD_PARTY_LOG_LEVEL:-WARNING}
      - ORCH_THIRD_PARTY_LOG_TO_FILE=${ORCH_THIRD_PARTY_LOG_TO_FILE:-1}
      - ORCH_THIRD_PARTY_FILE_LEVEL=${ORCH_THIRD_PARTY_FILE_LEVEL:-WARNING}
      - NUMBA_LOG_LEVEL=${NUMBA_LOG_LEVEL:-WARNING}
      - NUMBA_DEBUG=${NUMBA_DEBUG:-0}
      - FILM2_MODELS=/opt/models
      - FILM2_DATA=/srv/film2
      - ORCH_LOG_DIR=/workspace/logs
      - UPLOAD_DIR=/workspace/uploads
      # (rest unchanged...)
      - QWEN_BASE_URL=http://127.0.0.1:11435
      - QWEN_MODEL_ID=${QWEN_MODEL_ID:-huihui_ai/qwen3-abliterated:30b-a3b-q4_K_M}
      - GLM_OLLAMA_BASE_URL=${GLM_OLLAMA_BASE_URL:-http://127.0.0.1:11433}
      - GLM_MODEL_ID=${GLM_MODEL_ID:-hf.co/unsloth/GLM-4.6V-Flash-GGUF:BF16}
      - DEEPSEEK_CODER_OLLAMA_BASE_URL=${DEEPSEEK_CODER_OLLAMA_BASE_URL:-http://127.0.0.1:11436}
      - DEEPSEEK_CODER_MODEL_ID=${DEEPSEEK_CODER_MODEL_ID:-huihui_ai/deepseek-r1-abliterated:32b}
      - ICW_MODE=${ICW_MODE:-committee}
      - ICW_DISABLE=0
      - AUTO_EXECUTE_TOOLS=${AUTO_EXECUTE_TOOLS:-true}
      - ALLOW_TOOL_EXECUTION=${ALLOW_TOOL_EXECUTION:-true}
      - ENABLE_DEBATE=${ENABLE_DEBATE:-true}
      - MAX_DEBATE_TURNS=${MAX_DEBATE_TURNS:-1}
      - ABLATE=${ABLATE:-on}
      - ABLATE_EXPORT=${ABLATE_EXPORT:-on}
      - ABLATE_SCOPE=${ABLATE_SCOPE:-auto}
      - RAG_CACHE_TTL_SEC=${RAG_CACHE_TTL_SEC:-300}
      - DEFAULT_NUM_CTX=${DEFAULT_NUM_CTX:-32768}
      - DEFAULT_TEMPERATURE=${DEFAULT_TEMPERATURE:-0.3}
      - ENABLE_WEBSEARCH=${ENABLE_WEBSEARCH:-true}
      - SERPAPI_API_KEY
      - EXECUTOR_BASE_URL=http://127.0.0.1:8081
      - PLANNER_MODEL=${PLANNER_MODEL:-qwen3}
      - RVC_API_URL=${RVC_API_URL:-http://127.0.0.1:7863}
      - VOCAL_FIXER_API_URL=${VOCAL_FIXER_API_URL:-http://127.0.0.1:7864}
      - ASSEMBLER_API_URL=http://127.0.0.1:9095
      - DRT_API_URL=http://127.0.0.1:8086
      - HYVIDEO_API_URL=http://127.0.0.1:8094
      - POSTGRES_HOST=127.0.0.1
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ragdb
      - POSTGRES_USER=rag
      - POSTGRES_PASSWORD=ragpass
      - EMBEDDING_MODEL_NAME=${EMBEDDING_MODEL_NAME:-BAAI/bge-large-en-v1.5}
      - XTTS_API_URL=http://127.0.0.1:8020
      - WHISPER_API_URL=http://127.0.0.1:9090
      - FACEID_API_URL=http://127.0.0.1:7000
      - MUSIC_API_URL=http://127.0.0.1:7860
      - DEMUCS_API_URL=http://127.0.0.1:9101
      - COMFYUI_API_URL=http://192.168.50.222:8188
      - COMFY_WORKFLOW_PATH=/workspace/services/image/workflows/stock_smoke.json
      - COMFYUI_API_URLS=${COMFYUI_API_URLS:-}
      - COMFYUI_REPLICAS=${COMFYUI_REPLICAS:-1}
      - SCENE_SUBMIT_CONCURRENCY=${SCENE_SUBMIT_CONCURRENCY:-4}
      - PUBLIC_BASE_URL=${PUBLIC_BASE_URL:-}
      - VLM_API_URL=http://127.0.0.1:8050
      - OCR_API_URL=http://127.0.0.1:8070
      - AESTHETIC_HEAD_PATH=/opt/models/aesthetic/laion_v2_linear_L14.pt
      - MFA_API_URL=${MFA_API_URL:-http://127.0.0.1:7867}
      - VISION_REPAIR_API_URL=${VISION_REPAIR_API_URL:-http://127.0.0.1:8095}
      - VFI_API_URL=${VFI_API_URL:-http://127.0.0.1:8098}
      - UPSCALE_API_URL=${UPSCALE_API_URL:-http://127.0.0.1:8099}
      - INSIGHTFACE_HOME=/models/insightface
    command: ["python","-X","faulthandler","-m","uvicorn","app.main:app","--host","0.0.0.0","--port","8000","--log-level","info","--access-log","--use-colors","--http","h11","--loop","asyncio","--workers","4"]
    volumes:
      - ./:/workspace
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs
      - /mnt/ai-vols/models/film2:/opt/models
      - /mnt/ai-vols/training_data/film2:/srv/film2
      - ./assets/comfyui/input:/comfyui/input
      - ./assets/insightface:/models/insightface

  music:
    build:
      context: .
      dockerfile: services/music/Dockerfile
    container_name: music_service
    restart: unless-stopped
    runtime: nvidia
    devices:
      - "nvidia.com/gpu=all"
    depends_on:
      film2_bootstrap:
        condition: service_completed_successfully
    environment:
      - PYTHONUNBUFFERED=1
      - LOG_DIR=/workspace/logs
      - NVIDIA_VISIBLE_DEVICES=${MUSIC_GPU:-all}
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - UPLOAD_DIR=/workspace/uploads
    network_mode: host
    expose:
      - "7860"
    volumes:
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs

  xtts:
    build:
      context: .
      dockerfile: services/xtts/Dockerfile
      args:
        <<: *cu118_args
    container_name: xtts_service
    restart: unless-stopped
    runtime: nvidia
    devices:
      - "nvidia.com/gpu=all"
    depends_on:
      film2_bootstrap:
        condition: service_completed_successfully
    network_mode: host
    environment:
      - XTTS_MODEL_NAME=tts_models/multilingual/multi-dataset/xtts_v2
      - LOG_DIR=/workspace/logs
      - XTTS_VOICE_MODEL_MAP_PATH=/root/.local/share/tts/voice_model_map.json
      - COQUI_TOS_AGREED=1
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - HF_HOME=/models/hf
      - TRANSFORMERS_CACHE=/models/hf
      - TORCH_HOME=/models/torch
    expose:
      - "8020"
    shm_size: "1g"
    volumes:
      - /mnt/ai-vols/models/hf_cache:/models/hf
      - /mnt/ai-vols/models/torch_cache:/models/torch
      - /mnt/ai-vols/models/tts_cache:/root/.local/share/tts
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs
      - /mnt/ai-vols/models/film2:/opt/models:ro
      - /mnt/ai-vols/training_data/film2:/srv/film2

  whisper:
    build:
      context: ./services/whisper
      dockerfile: Dockerfile
    container_name: whisper_service
    restart: unless-stopped
    runtime: nvidia
    devices:
      - "nvidia.com/gpu=all"
    environment:
      - WHISPER_MODEL_NAME=large-v3
      - WHISPER_CPU_THREADS=8
      - LOG_DIR=/workspace/logs
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    expose:
      - "9090"
    volumes:
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs
      
  faceid:
    build:
      context: .
      dockerfile: services/faceid/Dockerfile
    container_name: faceid_service
    restart: unless-stopped
    runtime: nvidia
    devices:
      - "nvidia.com/gpu=all"
    # Match the rest of your stack so ORCH can hit 127.0.0.1:7000
    network_mode: host
    # Fix the temp-descriptor / writer/reader shared-memory crashes
    shm_size: "1g"
    ipc: host
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - LOG_DIR=/workspace/logs
      # Optional but helps if anything tries to use /tmp inside the container
      - TMPDIR=/workspace/uploads/tmp
      # If your faceid code honors this, it avoids surprise paths
      - INSIGHTFACE_HOME=/models/insightface
    volumes:
      # If your faceid expects insightface packs in a specific place,
      # mount to THAT place. Otherwise keep /opt/models.
      - /mnt/ai-vols/models/comfyui:/opt/models:ro
      # artifacts has /tmp already from ai_vols_init
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs


  vision_repair:
    build:
      context: ./services/vision_repair
      dockerfile: Dockerfile
    container_name: vision_repair
    restart: unless-stopped
    runtime: nvidia
    devices:
      - "nvidia.com/gpu=all"
    depends_on:
      film2_bootstrap:
        condition: service_completed_successfully
    environment:
      - NVIDIA_VISIBLE_DEVICES=${VISION_REPAIR_GPU:-all}
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - LOG_DIR=/workspace/logs
    network_mode: host
    expose:
      - "8095"
    volumes:
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs

  comfyui:
    build:
      context: ./services/comfyui
      dockerfile: Dockerfile
      args:
        <<: *cu118_args
    container_name: comfyui
    restart: unless-stopped
    runtime: nvidia
    network_mode: host
    depends_on:
      - comfyui_init
    devices:
      - "nvidia.com/gpu=all"
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    expose:
      - "8188"
    shm_size: "1g"
    volumes:
      - /mnt/ai-vols/models/comfyui:/comfyui/models
      - ./assets/comfyui/models/upscale:/comfyui/models/upscale
      - ./assets/comfyui/input:/comfyui/input
      - /mnt/ai-vols/artifacts:/comfyui/output
      - void_logs:/workspace/logs

  comfyui-1:
    build:
      context: ./services/comfyui
      dockerfile: Dockerfile
      args:
        <<: *cu118_args
    container_name: comfyui-1
    profiles: ["comfy-replicas"]
    restart: unless-stopped
    runtime: nvidia
    network_mode: host
    depends_on:
      - comfyui_init
    devices:
      - "nvidia.com/gpu=all"
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    expose:
      - "8188"
    volumes:
      - /mnt/ai-vols/models/comfyui:/comfyui/models
      - ./assets/comfyui/models/upscale:/comfyui/models/upscale
      - ./assets/comfyui/input:/comfyui/input
      - /mnt/ai-vols/artifacts:/comfyui/output
      - void_logs:/workspace/logs

  comfyui-2:
    build:
      context: ./services/comfyui
      dockerfile: Dockerfile
      args:
        <<: *cu118_args
    container_name: comfyui-2
    profiles: ["comfy-replicas"]
    restart: unless-stopped
    runtime: nvidia
    network_mode: host
    depends_on:
      - comfyui_init
    devices:
      - "nvidia.com/gpu=all"
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    expose:
      - "8188"
    volumes:
      - /mnt/ai-vols/models/comfyui:/comfyui/models
      - ./assets/comfyui/models/upscale:/comfyui/models/upscale
      - ./assets/comfyui/input:/comfyui/input
      - /mnt/ai-vols/artifacts:/comfyui/output
      - void_logs:/workspace/logs

  comfyui_init:
    build:
      context: ./services/comfyui_init
      dockerfile: Dockerfile
    container_name: comfyui_init
    network_mode: host
    depends_on:
      ai_vols_init:
        condition: service_completed_successfully
    environment:
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN:-}
      - COMFYUI_REPLICAS=${COMFYUI_REPLICAS:-1}
      - COMFYUI_GPU_DEVICES=${COMFYUI_GPU_DEVICES:-}
      - LOG_DIR=/workspace/logs
    volumes:
      - /mnt/ai-vols/models/comfyui:/comfyui/models
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs
    command: ["python", "/app/init_assets.py"]

  demucs:
    build:
      context: ./services/demucs
      dockerfile: Dockerfile
      args:
        <<: *cu118_args
    container_name: demucs_service
    restart: unless-stopped
    runtime: nvidia
    devices:
      - "nvidia.com/gpu=all"
    depends_on:
      film2_bootstrap:
        condition: service_completed_successfully
    environment:
      - NVIDIA_VISIBLE_DEVICES=${MUSIC_GPU:-all}
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - TORCH_HOME=/models/torch
      - LOG_DIR=/workspace/logs
    expose:
      - "9101"
    volumes:
      - /mnt/ai-vols/models/torch_cache:/models/torch
      - /mnt/ai-vols/models/demucs_cache:/root/.cache/demucs
      - /mnt/ai-vols/models/film2:/opt/models:ro
      - /mnt/ai-vols/training_data/film2:/srv/film2
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs

  vlm:
    build:
      context: ./services/vlm
      dockerfile: Dockerfile
      args:
        <<: *cu118_args
    container_name: vlm_service
    restart: unless-stopped
    runtime: nvidia
    devices:
      - "nvidia.com/gpu=all"
    depends_on:
      film2_bootstrap:
        condition: service_completed_successfully
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - LOG_DIR=/workspace/logs
      - HF_HOME=/models/hf
      - TRANSFORMERS_CACHE=/models/hf
      - TORCH_HOME=/models/torch
    expose:
      - "8050"
    shm_size: "1g"
    volumes:
      - /mnt/ai-vols/models/hf_cache:/models/hf
      - /mnt/ai-vols/models/torch_cache:/models/torch
      - /mnt/ai-vols/models/film2:/opt/models:ro
      - /mnt/ai-vols/training_data/film2:/srv/film2
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs

  ocr:
    build:
      context: ./services/ocr
      dockerfile: Dockerfile
    container_name: ocr_service
    restart: unless-stopped
    expose:
      - "8070"
    volumes:
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs

  executor:
    build:
      context: .
      dockerfile: executor/Dockerfile
    container_name: void_executor
    restart: unless-stopped
    network_mode: host
    environment:
      - WORKSPACE_DIR=/workspace
      - LOG_DIR=/workspace/logs
      - EXEC_MEMORY_MB=${EXEC_MEMORY_MB:-2048}
      - ALLOW_SHELL=${ALLOW_SHELL:-false}
      - SHELL_WHITELIST=${SHELL_WHITELIST:-}
      - ORCHESTRATOR_BASE_URL=http://127.0.0.1:8000
    volumes:
      - ./:/workspace
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs

  drt:
    build:
      context: .
      dockerfile: services/drt/Dockerfile
    container_name: deep_research_tool
    restart: unless-stopped
    shm_size: "1gb"
    environment:
      - PUBLIC_BASE_URL=${PUBLIC_BASE_URL:-}
      - LOG_DIR=/workspace/logs
      - DRT_RESPECT_ROBOTS=${DRT_RESPECT_ROBOTS:-true}
      - DRT_ROBOTS_TTL_S=${DRT_ROBOTS_TTL_S:-900}
      - DRT_RATE_MIN_GAP_MS=${DRT_RATE_MIN_GAP_MS:-200}
    expose:
      - "8086"
    volumes:
      - ./:/workspace
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs

  ablation:
    build:
      context: .
      dockerfile: services/ablation/Dockerfile
    container_name: ablation_layer
    restart: unless-stopped
    network_mode: host
    environment:
      - PUBLIC_BASE_URL=${PUBLIC_BASE_URL:-}
      - ABLCODER_URL=${ABLCODER_URL:-}
      - LOG_DIR=/workspace/logs
    expose:
      - "8096"
    volumes:
      - ./:/workspace
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs

  hunyuan_video:
    build:
      context: .
      dockerfile: services/hunyuan_video/Dockerfile
      args:
        <<: *cu118_args
    container_name: hunyuan_video_service
    restart: unless-stopped
    runtime: nvidia
    devices:
      - "nvidia.com/gpu=all"
    depends_on:
      film2_bootstrap:
        condition: service_completed_successfully
    environment:
      - NVIDIA_VISIBLE_DEVICES=${VIDEO_GPU:-all}
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - PYTHONUNBUFFERED=1
      - LOG_DIR=/workspace/logs
      - UPLOAD_DIR=/workspace/uploads
      - HYVIDEO_PORT=8094
      - HYVIDEO_MODEL_ID=/opt/models/hunyuan_diffusers
      - HYVIDEO_DEVICE=cuda:0
      - HYVIDEO_TRANSFORMER_DTYPE=bf16
      - HYVIDEO_PIPE_DTYPE=fp16
      - HYVIDEO_CPU_OFFLOAD=1
      - HYVIDEO_VAE_TILING=1
      - HYVIDEO_SR_ENABLE=1
      - HYVIDEO_SR_ROOT=/opt/models/hunyuan
      - HYVIDEO_SR_TRANSFORMER_SUBFOLDER=transformer/1080p_sr_distilled
      - HYVIDEO_SR_UPSAMPLER_SUBFOLDER=upsampler/1080p_sr_distilled
      - HYVIDEO_SR_SCHEDULER_SUBFOLDER=scheduler
      - HYVIDEO_SR_NUM_INFERENCE_STEPS=8
      - HYVIDEO_SR_GUIDANCE_SCALE=1.0
      - HYVIDEO_SR_TARGET_WIDTH=1920
      - HYVIDEO_SR_TARGET_HEIGHT=1080
      - HYVIDEO_SR_INTERNAL_MULTIPLE=16
      - HYVIDEO_ATTENTION_BACKEND=${HYVIDEO_ATTENTION_BACKEND:-}
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
      - HF_HOME=/opt/models/.hf
      - TRANSFORMERS_CACHE=/opt/models/.hf
      - TORCH_HOME=/opt/models/.torch
      - PUBLIC_BASE_URL=${PUBLIC_BASE_URL:-}
    network_mode: host
    expose:
      - "8094"
    shm_size: "2g"
    volumes:
      - /mnt/ai-vols/models/film2:/opt/models
      - /mnt/ai-vols/training_data/film2:/srv/film2
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs

  rife_vfi:
    build:
      context: .
      dockerfile: services/rife_vfi/Dockerfile
      args:
        <<: *cu118_args
    container_name: rife_vfi_service
    restart: unless-stopped
    runtime: nvidia
    devices:
      - "nvidia.com/gpu=all"
    depends_on:
      film2_bootstrap:
        condition: service_completed_successfully
    environment:
      - NVIDIA_VISIBLE_DEVICES=${VFI_GPU:-all}
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - PYTHONUNBUFFERED=1
      - LOG_DIR=/workspace/logs
      - UPLOAD_DIR=/workspace/uploads
      - RIFE_VFI_PORT=8098
      - RIFE_CODE_ROOT=/opt/practical_rife
      - RIFE_MODEL_DIR=/opt/models/rife_vfi/train_log
      - RIFE_UVICORN_WORKERS=${RIFE_UVICORN_WORKERS:-2}
      - PUBLIC_BASE_URL=${PUBLIC_BASE_URL:-}
    network_mode: host
    expose:
      - "8098"
    shm_size: "2g"
    volumes:
      - /mnt/ai-vols/models/film2:/opt/models:ro
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs

  upscale:
    build:
      context: .
      dockerfile: services/realesrgan_upscale/Dockerfile
      args:
        <<: *cu118_args
    container_name: upscale_service
    restart: unless-stopped
    runtime: nvidia
    devices:
      - "nvidia.com/gpu=all"
    depends_on:
      film2_bootstrap:
        condition: service_completed_successfully
    environment:
      - NVIDIA_VISIBLE_DEVICES=${UPSCALE_GPU:-all}
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - PYTHONUNBUFFERED=1
      - LOG_DIR=/workspace/logs
      - UPLOAD_DIR=/workspace/uploads
      - PUBLIC_BASE_URL=${PUBLIC_BASE_URL:-}
      - UPSCALE_PORT=8099
      - UPSCALE_UVICORN_WORKERS=${UPSCALE_UVICORN_WORKERS:-1}
      - REALESRGAN_CODE_ROOT=/opt/realesrgan
      - REALESRGAN_WEIGHTS_SRC=/opt/models/realesrgan/weights
      - REALESRGAN_MODEL_NAME=${REALESRGAN_MODEL_NAME:-RealESRGAN_x4plus}
      - REALESRGAN_TILE=${REALESRGAN_TILE:-0}
      - REALESRGAN_EXT=${REALESRGAN_EXT:-png}
      - REALESRGAN_SUFFIX=${REALESRGAN_SUFFIX:-up}
    network_mode: host
    expose:
      - "8099"
    shm_size: "2g"
    volumes:
      - /mnt/ai-vols/models/film2:/opt/models:ro
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs

  chatui:
    build:
      context: .
      dockerfile: services/chatui/Dockerfile
    container_name: chatui
    restart: unless-stopped
    network_mode: host
    environment:
      - ORCHESTRATOR_URL=http://127.0.0.1:8000
      - PUBLIC_ORCH_BASE=http://192.168.50.222:8000
      - POSTGRES_HOST=127.0.0.1
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ragdb
      - POSTGRES_USER=rag
      - POSTGRES_PASSWORD=ragpass
    volumes:
      - /mnt/ai-vols/artifacts:/workspace/uploads
      - void_logs:/workspace/logs

  valkey:
    image: valkey/valkey:8
    container_name: valkey
    restart: unless-stopped
    network_mode: host
    command:
      - valkey-server
      - "--port"
      - "${VALKEY_PORT:-6380}"
      - "--save"
      - ""
      - "--appendonly"
      - "no"

  searxng:
    build:
      context: ./services/searxng
      dockerfile: Dockerfile
    container_name: searxng
    restart: unless-stopped
    network_mode: host
    depends_on:
      - valkey
    environment:
      - BIND_ADDRESS=0.0.0.0:${SEARXNG_PORT:-8090}
      - SEARXNG_SETTINGS_PATH=/etc/searxng/settings.yml
      - SEARXNG_BASE_URL=http://localhost:${SEARXNG_PORT:-8090}
      - FORCE_OWNERSHIP=false
    volumes:
      - ./services/searxng/settings.yml:/etc/searxng/settings.yml

volumes:
  pgvector_data: {}
  void_logs: {}
  rvc_logs: {}
